2024-04-24 22:49:48.647946: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-04-24 22:49:48.648346: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-04-24 22:49:48.649576: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-04-24 22:49:48.656286: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-24 22:49:49.898995: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[nltk_data] Downloading package punkt to
[nltk_data]     /home/abdelrahman.sadallah/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
`low_cpu_mem_usage` was None, now set to True since model is quantized.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [03:56<03:56, 236.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [05:06<00:00, 138.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [05:06<00:00, 153.46s/it]
  0%|          | 0/36 [00:00<?, ?it/s]/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.0001` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
  3%|▎         | 1/36 [01:14<43:13, 74.11s/it]  6%|▌         | 2/36 [02:16<38:14, 67.48s/it]  8%|▊         | 3/36 [02:48<28:10, 51.21s/it] 11%|█         | 4/36 [03:22<23:31, 44.11s/it] 14%|█▍        | 5/36 [04:35<28:17, 54.74s/it] 17%|█▋        | 6/36 [05:16<24:57, 49.93s/it] 19%|█▉        | 7/36 [05:56<22:35, 46.75s/it] 22%|██▏       | 8/36 [06:33<20:22, 43.66s/it] 25%|██▌       | 9/36 [07:39<22:48, 50.67s/it] 28%|██▊       | 10/36 [08:17<20:12, 46.64s/it] 31%|███       | 11/36 [09:08<20:01, 48.07s/it] 33%|███▎      | 12/36 [09:35<16:39, 41.64s/it] 36%|███▌      | 13/36 [10:18<16:10, 42.18s/it] 39%|███▉      | 14/36 [11:16<17:12, 46.94s/it] 42%|████▏     | 15/36 [11:38<13:43, 39.22s/it] 44%|████▍     | 16/36 [12:54<16:47, 50.39s/it] 47%|████▋     | 17/36 [14:07<18:08, 57.28s/it] 50%|█████     | 18/36 [14:54<16:12, 54.00s/it] 53%|█████▎    | 19/36 [15:35<14:14, 50.26s/it] 56%|█████▌    | 20/36 [16:23<13:12, 49.53s/it] 58%|█████▊    | 21/36 [16:54<11:01, 44.10s/it] 61%|██████    | 22/36 [18:07<12:17, 52.67s/it] 64%|██████▍   | 23/36 [19:17<12:33, 57.95s/it] 67%|██████▋   | 24/36 [19:36<09:14, 46.20s/it] 69%|██████▉   | 25/36 [20:07<07:39, 41.73s/it] 72%|███████▏  | 26/36 [20:53<07:08, 42.88s/it] 75%|███████▌  | 27/36 [22:08<07:52, 52.54s/it] 78%|███████▊  | 28/36 [23:09<07:19, 54.97s/it] 81%|████████  | 29/36 [24:14<06:47, 58.16s/it] 83%|████████▎ | 30/36 [24:47<05:02, 50.44s/it] 86%|████████▌ | 31/36 [25:10<03:31, 42.40s/it] 89%|████████▉ | 32/36 [26:26<03:29, 52.39s/it] 92%|█████████▏| 33/36 [27:40<02:56, 58.87s/it] 94%|█████████▍| 34/36 [28:21<01:47, 53.64s/it] 97%|█████████▋| 35/36 [28:47<00:45, 45.22s/it]100%|██████████| 36/36 [30:15<00:00, 58.18s/it]100%|██████████| 36/36 [30:15<00:00, 50.44s/it]
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
