2024-04-20 22:56:07.609132: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-04-20 22:56:07.609821: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-04-20 22:56:07.610746: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-04-20 22:56:07.616362: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-20 22:56:08.661913: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[nltk_data] Downloading package punkt to
[nltk_data]     /home/abdelrahman.sadallah/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/torch/__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:22<13:08, 22.54s/it]  6%|▌         | 2/36 [00:43<12:16, 21.66s/it]  8%|▊         | 3/36 [01:09<12:55, 23.50s/it] 11%|█         | 4/36 [01:32<12:30, 23.45s/it] 14%|█▍        | 5/36 [01:54<11:45, 22.75s/it] 17%|█▋        | 6/36 [02:19<11:49, 23.65s/it] 19%|█▉        | 7/36 [02:52<12:52, 26.65s/it] 22%|██▏       | 8/36 [03:17<12:14, 26.24s/it] 25%|██▌       | 9/36 [03:53<13:07, 29.17s/it] 28%|██▊       | 10/36 [04:15<11:43, 27.06s/it] 31%|███       | 11/36 [04:44<11:29, 27.58s/it] 33%|███▎      | 12/36 [05:14<11:17, 28.25s/it] 36%|███▌      | 13/36 [05:27<09:03, 23.64s/it] 39%|███▉      | 14/36 [05:56<09:16, 25.29s/it] 42%|████▏     | 15/36 [06:30<09:46, 27.93s/it] 44%|████▍     | 16/36 [06:49<08:26, 25.33s/it] 47%|████▋     | 17/36 [07:15<08:03, 25.46s/it] 50%|█████     | 18/36 [07:53<08:46, 29.23s/it] 53%|█████▎    | 19/36 [08:16<07:46, 27.41s/it] 56%|█████▌    | 20/36 [08:48<07:37, 28.62s/it] 58%|█████▊    | 21/36 [09:04<06:15, 25.02s/it] 61%|██████    | 22/36 [09:25<05:33, 23.81s/it] 64%|██████▍   | 23/36 [09:49<05:10, 23.85s/it] 67%|██████▋   | 24/36 [10:13<04:45, 23.77s/it] 69%|██████▉   | 25/36 [10:37<04:23, 23.95s/it] 72%|███████▏  | 26/36 [11:01<03:58, 23.84s/it] 75%|███████▌  | 27/36 [11:37<04:07, 27.53s/it] 78%|███████▊  | 28/36 [11:52<03:11, 23.89s/it] 81%|████████  | 29/36 [12:17<02:49, 24.28s/it] 83%|████████▎ | 30/36 [12:47<02:35, 25.84s/it] 86%|████████▌ | 31/36 [13:33<02:39, 31.97s/it] 89%|████████▉ | 32/36 [13:59<02:00, 30.14s/it] 92%|█████████▏| 33/36 [14:29<01:30, 30.03s/it] 94%|█████████▍| 34/36 [14:46<00:52, 26.15s/it] 97%|█████████▋| 35/36 [15:05<00:23, 23.97s/it]100%|██████████| 36/36 [15:47<00:00, 29.32s/it]100%|██████████| 36/36 [15:47<00:00, 26.31s/it]
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Warning: Empty candidate sentence detected; setting raw BERTscores to 0.
Warning: Empty candidate sentence detected; setting raw BERTscores to 0.
Traceback (most recent call last):
  File "/home/abdelrahman.sadallah/mbzuai/UWFe/evaluate_llm.py", line 293, in <module>
    with open(save_file, 'w') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'outputs/outputs/Meta-Llama-3-8B-Instruct_metrics_5-shots_True-explicit.txt'
[2024-04-20 23:13:14,595] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 2421311) of binary: /home/abdelrahman.sadallah/mambaforge/envs/nlp/bin/python
Traceback (most recent call last):
  File "/home/abdelrahman.sadallah/mambaforge/envs/nlp/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
evaluate_llm.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-20_23:13:14
  host      : gpu-05
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 2421311)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
