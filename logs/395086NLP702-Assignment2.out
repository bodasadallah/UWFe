model_name_or_path cognitivecomputations/dolphin-2.8-mistral-7b-v02
wandb_project nlp804-UWFE-dolphin
use_flash_attention_2 True
dataset boda/kaneko_data
prompt_key prompt
num_shots 0
explicit_errors False
output_dir /l/users/abdelrahman.sadallah/UWFE-Mixtral
overwrite_output_dir False
do_train False
do_eval True
do_predict False
evaluation_strategy IntervalStrategy.STEPS
prediction_loss_only False
per_device_train_batch_size 4
per_device_eval_batch_size 4
per_gpu_train_batch_size None
per_gpu_eval_batch_size None
gradient_accumulation_steps 1
eval_accumulation_steps None
eval_delay 0
learning_rate 1e-06
weight_decay 0.01
adam_beta1 0.9
adam_beta2 0.999
adam_epsilon 1e-08
max_grad_norm 1.0
num_train_epochs 3.0
max_steps 10000
lr_scheduler_type SchedulerType.LINEAR
lr_scheduler_kwargs {}
warmup_ratio 0.07
warmup_steps 0
log_level passive
log_level_replica warning
log_on_each_node True
logging_dir /l/users/abdelrahman.sadallah/UWFE-Mixtral/runs/Apr10_22-39-09_gpu-13
logging_strategy IntervalStrategy.STEPS
logging_first_step False
logging_steps 100
logging_nan_inf_filter True
save_strategy IntervalStrategy.STEPS
save_steps 500
save_total_limit 3
save_safetensors True
save_on_each_node False
save_only_model False
no_cuda False
use_cpu False
use_mps_device False
seed 42
data_seed None
jit_mode_eval False
use_ipex False
bf16 False
fp16 False
fp16_opt_level O1
half_precision_backend auto
bf16_full_eval False
fp16_full_eval False
tf32 None
local_rank 0
ddp_backend None
tpu_num_cores None
tpu_metrics_debug False
debug []
dataloader_drop_last False
eval_steps 500
dataloader_num_workers 0
dataloader_prefetch_factor None
past_index -1
run_name /l/users/abdelrahman.sadallah/UWFE-Mixtral
disable_tqdm False
remove_unused_columns True
label_names None
load_best_model_at_end True
metric_for_best_model loss
greater_is_better False
ignore_data_skip False
fsdp []
fsdp_min_num_params 0
fsdp_config {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}
fsdp_transformer_layer_cls_to_wrap None
accelerator_config AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True)
deepspeed None
label_smoothing_factor 0.0
optim OptimizerNames.ADAMW_TORCH
optim_args None
adafactor False
group_by_length False
length_column_name length
report_to ['tensorboard', 'wandb']
ddp_find_unused_parameters None
ddp_bucket_cap_mb None
ddp_broadcast_buffers None
dataloader_pin_memory True
dataloader_persistent_workers False
skip_memory_metrics True
use_legacy_prediction_loop False
push_to_hub False
resume_from_checkpoint None
hub_model_id None
hub_strategy HubStrategy.EVERY_SAVE
hub_token None
hub_private_repo False
hub_always_push False
gradient_checkpointing False
gradient_checkpointing_kwargs None
include_inputs_for_metrics False
fp16_backend auto
push_to_hub_model_id None
push_to_hub_organization None
push_to_hub_token None
mp_parameters 
auto_find_batch_size False
full_determinism False
torchdynamo None
ray_scope last
ddp_timeout 1800
torch_compile False
torch_compile_backend None
torch_compile_mode None
dispatch_batches None
split_batches None
include_tokens_per_second False
include_num_input_tokens_seen False
neftune_noise_alpha None
sortish_sampler False
predict_with_generate False
generation_max_length None
generation_num_beams None
generation_config None
distributed_state Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

_n_gpu 1
__cached__setup_devices cuda:0
deepspeed_plugin None
Loading the datasets
{'loss': 2.1964, 'grad_norm': 1.285356879234314, 'learning_rate': 1.426533523537803e-07, 'epoch': 0.31}
{'loss': 2.177, 'grad_norm': 1.1122621297836304, 'learning_rate': 2.853067047075606e-07, 'epoch': 0.62}
{'loss': 2.0567, 'grad_norm': 1.2400513887405396, 'learning_rate': 4.2796005706134093e-07, 'epoch': 0.93}
{'loss': 1.87, 'grad_norm': 1.794363260269165, 'learning_rate': 5.706134094151212e-07, 'epoch': 1.23}
{'loss': 1.5259, 'grad_norm': 0.8391618132591248, 'learning_rate': 7.132667617689015e-07, 'epoch': 1.54}
{'eval_loss': 1.3250950574874878, 'eval_runtime': 19.9078, 'eval_samples_per_second': 7.233, 'eval_steps_per_second': 1.808, 'epoch': 1.54}
{'loss': 1.3965, 'grad_norm': 0.8661797046661377, 'learning_rate': 8.559201141226819e-07, 'epoch': 1.85}
{'loss': 1.3001, 'grad_norm': 0.7809984087944031, 'learning_rate': 9.985734664764621e-07, 'epoch': 2.16}
{'loss': 1.2501, 'grad_norm': 0.8413594365119934, 'learning_rate': 9.893536939455855e-07, 'epoch': 2.47}
{'loss': 1.1997, 'grad_norm': 0.9968289732933044, 'learning_rate': 9.78599849446177e-07, 'epoch': 2.78}
{'loss': 1.2133, 'grad_norm': 0.8802772760391235, 'learning_rate': 9.678460049467684e-07, 'epoch': 3.09}
{'eval_loss': 1.0116305351257324, 'eval_runtime': 19.9091, 'eval_samples_per_second': 7.233, 'eval_steps_per_second': 1.808, 'epoch': 3.09}
{'loss': 1.1754, 'grad_norm': 0.9056565165519714, 'learning_rate': 9.570921604473599e-07, 'epoch': 3.4}
{'loss': 1.1494, 'grad_norm': 1.2498787641525269, 'learning_rate': 9.463383159479513e-07, 'epoch': 3.7}
{'loss': 1.1707, 'grad_norm': 1.08112633228302, 'learning_rate': 9.355844714485428e-07, 'epoch': 4.01}
{'loss': 1.1293, 'grad_norm': 1.1253124475479126, 'learning_rate': 9.248306269491342e-07, 'epoch': 4.32}
{'loss': 1.1418, 'grad_norm': 1.124163269996643, 'learning_rate': 9.140767824497257e-07, 'epoch': 4.63}
{'eval_loss': 0.9678385257720947, 'eval_runtime': 19.9183, 'eval_samples_per_second': 7.23, 'eval_steps_per_second': 1.807, 'epoch': 4.63}
{'loss': 1.1234, 'grad_norm': 1.0593791007995605, 'learning_rate': 9.033229379503173e-07, 'epoch': 4.94}
{'loss': 1.11, 'grad_norm': 1.1305491924285889, 'learning_rate': 8.925690934509087e-07, 'epoch': 5.25}
{'loss': 1.1195, 'grad_norm': 1.60916006565094, 'learning_rate': 8.818152489515002e-07, 'epoch': 5.56}
{'loss': 1.0916, 'grad_norm': 1.4369018077850342, 'learning_rate': 8.710614044520915e-07, 'epoch': 5.86}
{'loss': 1.0936, 'grad_norm': 1.6274725198745728, 'learning_rate': 8.60307559952683e-07, 'epoch': 6.17}
{'eval_loss': 0.948675274848938, 'eval_runtime': 19.9484, 'eval_samples_per_second': 7.219, 'eval_steps_per_second': 1.805, 'epoch': 6.17}
{'loss': 1.1013, 'grad_norm': 1.3562058210372925, 'learning_rate': 8.495537154532744e-07, 'epoch': 6.48}
{'loss': 1.076, 'grad_norm': 1.3728680610656738, 'learning_rate': 8.387998709538659e-07, 'epoch': 6.79}
{'loss': 1.0754, 'grad_norm': 1.4785221815109253, 'learning_rate': 8.280460264544575e-07, 'epoch': 7.1}
{'loss': 1.0769, 'grad_norm': 1.236851692199707, 'learning_rate': 8.172921819550489e-07, 'epoch': 7.41}
{'loss': 1.0666, 'grad_norm': 1.4619274139404297, 'learning_rate': 8.065383374556404e-07, 'epoch': 7.72}
{'eval_loss': 0.9350276589393616, 'eval_runtime': 19.9363, 'eval_samples_per_second': 7.223, 'eval_steps_per_second': 1.806, 'epoch': 7.72}
{'loss': 1.0583, 'grad_norm': 1.8254616260528564, 'learning_rate': 7.957844929562318e-07, 'epoch': 8.02}
{'loss': 1.0732, 'grad_norm': 1.80806565284729, 'learning_rate': 7.850306484568233e-07, 'epoch': 8.33}
{'loss': 1.0563, 'grad_norm': 1.8198367357254028, 'learning_rate': 7.742768039574148e-07, 'epoch': 8.64}
{'loss': 1.0382, 'grad_norm': 2.084756374359131, 'learning_rate': 7.635229594580061e-07, 'epoch': 8.95}
{'loss': 1.0468, 'grad_norm': 1.7511290311813354, 'learning_rate': 7.527691149585977e-07, 'epoch': 9.26}
{'eval_loss': 0.9238255620002747, 'eval_runtime': 19.9367, 'eval_samples_per_second': 7.223, 'eval_steps_per_second': 1.806, 'epoch': 9.26}
{'loss': 1.0393, 'grad_norm': 1.8762208223342896, 'learning_rate': 7.420152704591891e-07, 'epoch': 9.57}
{'loss': 1.0358, 'grad_norm': 1.7944577932357788, 'learning_rate': 7.312614259597806e-07, 'epoch': 9.88}
{'loss': 1.0412, 'grad_norm': 1.763375163078308, 'learning_rate': 7.20507581460372e-07, 'epoch': 10.19}
{'loss': 1.0186, 'grad_norm': 1.7623366117477417, 'learning_rate': 7.097537369609635e-07, 'epoch': 10.49}
{'loss': 1.0329, 'grad_norm': 1.8141398429870605, 'learning_rate': 6.98999892461555e-07, 'epoch': 10.8}
{'eval_loss': 0.9154033660888672, 'eval_runtime': 19.9365, 'eval_samples_per_second': 7.223, 'eval_steps_per_second': 1.806, 'epoch': 10.8}
{'loss': 1.0147, 'grad_norm': 1.6122808456420898, 'learning_rate': 6.882460479621465e-07, 'epoch': 11.11}
{'loss': 1.0308, 'grad_norm': 1.859663963317871, 'learning_rate': 6.77492203462738e-07, 'epoch': 11.42}
{'loss': 1.0002, 'grad_norm': 1.9649988412857056, 'learning_rate': 6.667383589633293e-07, 'epoch': 11.73}
{'loss': 0.9948, 'grad_norm': 1.8055429458618164, 'learning_rate': 6.559845144639208e-07, 'epoch': 12.04}
{'loss': 0.9991, 'grad_norm': 2.340942859649658, 'learning_rate': 6.452306699645122e-07, 'epoch': 12.35}
{'eval_loss': 0.9090295433998108, 'eval_runtime': 19.9134, 'eval_samples_per_second': 7.231, 'eval_steps_per_second': 1.808, 'epoch': 12.35}
{'loss': 1.0058, 'grad_norm': 1.7229297161102295, 'learning_rate': 6.344768254651037e-07, 'epoch': 12.65}
{'loss': 1.0103, 'grad_norm': 1.8979943990707397, 'learning_rate': 6.237229809656952e-07, 'epoch': 12.96}
{'loss': 0.9694, 'grad_norm': 1.9236195087432861, 'learning_rate': 6.129691364662867e-07, 'epoch': 13.27}
{'loss': 1.0046, 'grad_norm': 2.3794496059417725, 'learning_rate': 6.022152919668782e-07, 'epoch': 13.58}
{'loss': 0.9794, 'grad_norm': 2.2673017978668213, 'learning_rate': 5.914614474674696e-07, 'epoch': 13.89}
{'eval_loss': 0.9032915830612183, 'eval_runtime': 19.9551, 'eval_samples_per_second': 7.216, 'eval_steps_per_second': 1.804, 'epoch': 13.89}
{'loss': 0.9967, 'grad_norm': 2.169475555419922, 'learning_rate': 5.807076029680611e-07, 'epoch': 14.2}
{'loss': 0.9848, 'grad_norm': 2.138998508453369, 'learning_rate': 5.699537584686525e-07, 'epoch': 14.51}
{'loss': 0.9926, 'grad_norm': 2.0195963382720947, 'learning_rate': 5.591999139692439e-07, 'epoch': 14.81}
{'loss': 0.9656, 'grad_norm': 2.36667537689209, 'learning_rate': 5.484460694698354e-07, 'epoch': 15.12}
{'loss': 0.9694, 'grad_norm': 2.0573554039001465, 'learning_rate': 5.376922249704269e-07, 'epoch': 15.43}
{'eval_loss': 0.8968106508255005, 'eval_runtime': 19.9475, 'eval_samples_per_second': 7.219, 'eval_steps_per_second': 1.805, 'epoch': 15.43}
{'loss': 0.9723, 'grad_norm': 2.402536392211914, 'learning_rate': 5.269383804710184e-07, 'epoch': 15.74}
{'loss': 0.9753, 'grad_norm': 2.4804444313049316, 'learning_rate': 5.161845359716098e-07, 'epoch': 16.05}
{'loss': 0.9612, 'grad_norm': 2.296342611312866, 'learning_rate': 5.054306914722013e-07, 'epoch': 16.36}
{'loss': 0.9538, 'grad_norm': 2.3993961811065674, 'learning_rate': 4.946768469727927e-07, 'epoch': 16.67}
{'loss': 0.968, 'grad_norm': 1.997053861618042, 'learning_rate': 4.839230024733842e-07, 'epoch': 16.98}
{'eval_loss': 0.8914160132408142, 'eval_runtime': 19.945, 'eval_samples_per_second': 7.22, 'eval_steps_per_second': 1.805, 'epoch': 16.98}
{'loss': 0.9755, 'grad_norm': 2.2423043251037598, 'learning_rate': 4.7316915797397566e-07, 'epoch': 17.28}
{'loss': 0.9522, 'grad_norm': 2.7282285690307617, 'learning_rate': 4.624153134745671e-07, 'epoch': 17.59}
{'loss': 0.9327, 'grad_norm': 2.291194438934326, 'learning_rate': 4.5166146897515863e-07, 'epoch': 17.9}
{'loss': 0.9743, 'grad_norm': 2.631079912185669, 'learning_rate': 4.409076244757501e-07, 'epoch': 18.21}
{'loss': 0.9436, 'grad_norm': 2.4709830284118652, 'learning_rate': 4.301537799763415e-07, 'epoch': 18.52}
{'eval_loss': 0.887162446975708, 'eval_runtime': 19.9788, 'eval_samples_per_second': 7.208, 'eval_steps_per_second': 1.802, 'epoch': 18.52}
{'loss': 0.959, 'grad_norm': 2.4389724731445312, 'learning_rate': 4.1939993547693295e-07, 'epoch': 18.83}
{'loss': 0.9417, 'grad_norm': 2.2980828285217285, 'learning_rate': 4.0864609097752446e-07, 'epoch': 19.14}
{'loss': 0.9324, 'grad_norm': 2.7826952934265137, 'learning_rate': 3.978922464781159e-07, 'epoch': 19.44}
{'loss': 0.9495, 'grad_norm': 2.700192928314209, 'learning_rate': 3.871384019787074e-07, 'epoch': 19.75}
{'loss': 0.949, 'grad_norm': 2.315141201019287, 'learning_rate': 3.7638455747929883e-07, 'epoch': 20.06}
{'eval_loss': 0.8838177919387817, 'eval_runtime': 19.9559, 'eval_samples_per_second': 7.216, 'eval_steps_per_second': 1.804, 'epoch': 20.06}
{'loss': 0.955, 'grad_norm': 2.6840431690216064, 'learning_rate': 3.656307129798903e-07, 'epoch': 20.37}
{'loss': 0.9235, 'grad_norm': 2.5414340496063232, 'learning_rate': 3.5487686848048175e-07, 'epoch': 20.68}
{'loss': 0.9301, 'grad_norm': 2.3291378021240234, 'learning_rate': 3.4412302398107326e-07, 'epoch': 20.99}
{'loss': 0.9348, 'grad_norm': 2.313673496246338, 'learning_rate': 3.3336917948166466e-07, 'epoch': 21.3}
{'loss': 0.9353, 'grad_norm': 2.3020918369293213, 'learning_rate': 3.226153349822561e-07, 'epoch': 21.6}
{'eval_loss': 0.8808527588844299, 'eval_runtime': 19.9662, 'eval_samples_per_second': 7.212, 'eval_steps_per_second': 1.803, 'epoch': 21.6}
{'loss': 0.9174, 'grad_norm': 2.8649959564208984, 'learning_rate': 3.118614904828476e-07, 'epoch': 21.91}
{'loss': 0.93, 'grad_norm': 2.693619966506958, 'learning_rate': 3.011076459834391e-07, 'epoch': 22.22}
{'loss': 0.9194, 'grad_norm': 2.481031656265259, 'learning_rate': 2.9035380148403055e-07, 'epoch': 22.53}
{'loss': 0.9369, 'grad_norm': 2.667710542678833, 'learning_rate': 2.7959995698462195e-07, 'epoch': 22.84}
{'loss': 0.9293, 'grad_norm': 2.7858357429504395, 'learning_rate': 2.6884611248521346e-07, 'epoch': 23.15}
{'eval_loss': 0.8782157897949219, 'eval_runtime': 19.9319, 'eval_samples_per_second': 7.225, 'eval_steps_per_second': 1.806, 'epoch': 23.15}
{'loss': 0.9211, 'grad_norm': 2.6608009338378906, 'learning_rate': 2.580922679858049e-07, 'epoch': 23.46}
{'loss': 0.9345, 'grad_norm': 2.704591989517212, 'learning_rate': 2.473384234863964e-07, 'epoch': 23.77}
{'loss': 0.9083, 'grad_norm': 2.3143434524536133, 'learning_rate': 2.3658457898698783e-07, 'epoch': 24.07}
{'loss': 0.9215, 'grad_norm': 2.634446620941162, 'learning_rate': 2.2583073448757932e-07, 'epoch': 24.38}
{'loss': 0.9256, 'grad_norm': 2.535311698913574, 'learning_rate': 2.1507688998817075e-07, 'epoch': 24.69}
{'eval_loss': 0.8760602474212646, 'eval_runtime': 19.898, 'eval_samples_per_second': 7.237, 'eval_steps_per_second': 1.809, 'epoch': 24.69}
{'loss': 0.9039, 'grad_norm': 3.5156056880950928, 'learning_rate': 2.0432304548876223e-07, 'epoch': 25.0}
{'loss': 0.9044, 'grad_norm': 3.5334086418151855, 'learning_rate': 1.935692009893537e-07, 'epoch': 25.31}
{'loss': 0.9129, 'grad_norm': 3.2498693466186523, 'learning_rate': 1.8281535648994515e-07, 'epoch': 25.62}
{'loss': 0.9325, 'grad_norm': 2.642974853515625, 'learning_rate': 1.7206151199053663e-07, 'epoch': 25.93}
{'loss': 0.9121, 'grad_norm': 2.861116886138916, 'learning_rate': 1.6130766749112806e-07, 'epoch': 26.23}
{'eval_loss': 0.8742824792861938, 'eval_runtime': 19.9051, 'eval_samples_per_second': 7.234, 'eval_steps_per_second': 1.809, 'epoch': 26.23}
{'loss': 0.8843, 'grad_norm': 2.9923410415649414, 'learning_rate': 1.5055382299171954e-07, 'epoch': 26.54}
{'loss': 0.9205, 'grad_norm': 2.981912612915039, 'learning_rate': 1.3979997849231097e-07, 'epoch': 26.85}
{'loss': 0.9335, 'grad_norm': 3.1958677768707275, 'learning_rate': 1.2904613399290246e-07, 'epoch': 27.16}
{'loss': 0.9154, 'grad_norm': 2.9356887340545654, 'learning_rate': 1.1829228949349392e-07, 'epoch': 27.47}
{'loss': 0.9042, 'grad_norm': 2.8852155208587646, 'learning_rate': 1.0753844499408537e-07, 'epoch': 27.78}
{'eval_loss': 0.8728697299957275, 'eval_runtime': 19.9283, 'eval_samples_per_second': 7.226, 'eval_steps_per_second': 1.806, 'epoch': 27.78}
{'loss': 0.9117, 'grad_norm': 2.679684638977051, 'learning_rate': 9.678460049467684e-08, 'epoch': 28.09}
{'loss': 0.918, 'grad_norm': 2.620267629623413, 'learning_rate': 8.603075599526831e-08, 'epoch': 28.4}
{'loss': 0.9074, 'grad_norm': 2.6652464866638184, 'learning_rate': 7.527691149585977e-08, 'epoch': 28.7}
{'loss': 0.8892, 'grad_norm': 2.657580852508545, 'learning_rate': 6.452306699645123e-08, 'epoch': 29.01}
{'loss': 0.9144, 'grad_norm': 2.5658767223358154, 'learning_rate': 5.376922249704269e-08, 'epoch': 29.32}
{'eval_loss': 0.8722928166389465, 'eval_runtime': 19.9023, 'eval_samples_per_second': 7.235, 'eval_steps_per_second': 1.809, 'epoch': 29.32}
{'loss': 0.8958, 'grad_norm': 2.8456649780273438, 'learning_rate': 4.301537799763416e-08, 'epoch': 29.63}
{'loss': 0.904, 'grad_norm': 2.27154803276062, 'learning_rate': 3.2261533498225615e-08, 'epoch': 29.94}
{'loss': 0.9142, 'grad_norm': 3.471649408340454, 'learning_rate': 2.150768899881708e-08, 'epoch': 30.25}
{'loss': 0.9151, 'grad_norm': 2.8693151473999023, 'learning_rate': 1.075384449940854e-08, 'epoch': 30.56}
{'loss': 0.9136, 'grad_norm': 3.6636688709259033, 'learning_rate': 0.0, 'epoch': 30.86}
{'eval_loss': 0.8719987869262695, 'eval_runtime': 19.8976, 'eval_samples_per_second': 7.237, 'eval_steps_per_second': 1.809, 'epoch': 30.86}
{'train_runtime': 17892.2405, 'train_samples_per_second': 2.236, 'train_steps_per_second': 0.559, 'train_loss': 1.0471567138671876, 'epoch': 30.86}
ending 
