2024-04-21 08:26:54.416352: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-04-21 08:26:54.416687: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-04-21 08:26:54.417741: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-04-21 08:26:54.424046: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-21 08:26:56.110346: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[nltk_data] Downloading package punkt to
[nltk_data]     /home/abdelrahman.sadallah/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
Map:   0%|          | 0/144 [00:00<?, ? examples/s]Map:  34%|███▍      | 49/144 [00:00<00:00, 481.63 examples/s]Map:  77%|███████▋  | 111/144 [00:00<00:00, 251.64 examples/s]Map: 100%|██████████| 144/144 [00:00<00:00, 302.71 examples/s]
/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/torch/__init__.py:696: UserWarning: torch.set_default_tensor_type() is deprecated as of PyTorch 2.1, please use torch.set_default_dtype() and torch.set_default_device() as alternatives. (Triggered internally at ../torch/csrc/tensor/python_tensor.cpp:451.)
  _C._set_default_tensor_type(t)
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [00:12<07:19, 12.55s/it]  6%|▌         | 2/36 [00:28<08:19, 14.68s/it]  8%|▊         | 3/36 [00:44<08:24, 15.29s/it] 11%|█         | 4/36 [00:55<07:12, 13.51s/it] 14%|█▍        | 5/36 [01:20<09:03, 17.53s/it] 17%|█▋        | 6/36 [01:38<08:52, 17.74s/it] 19%|█▉        | 7/36 [01:55<08:28, 17.53s/it] 22%|██▏       | 8/36 [02:16<08:39, 18.55s/it] 25%|██▌       | 9/36 [02:38<08:56, 19.85s/it] 28%|██▊       | 10/36 [03:04<09:22, 21.65s/it] 31%|███       | 11/36 [03:17<07:58, 19.13s/it] 33%|███▎      | 12/36 [03:32<07:02, 17.60s/it] 36%|███▌      | 13/36 [03:50<06:53, 17.96s/it] 39%|███▉      | 14/36 [04:08<06:30, 17.74s/it] 42%|████▏     | 15/36 [04:33<06:59, 19.98s/it] 44%|████▍     | 16/36 [04:53<06:40, 20.03s/it] 47%|████▋     | 17/36 [05:05<05:35, 17.66s/it] 50%|█████     | 18/36 [05:22<05:14, 17.48s/it] 53%|█████▎    | 19/36 [05:43<05:13, 18.44s/it] 56%|█████▌    | 20/36 [05:54<04:21, 16.36s/it] 58%|█████▊    | 21/36 [06:19<04:42, 18.82s/it] 61%|██████    | 22/36 [06:36<04:15, 18.28s/it] 64%|██████▍   | 23/36 [06:56<04:05, 18.88s/it] 67%|██████▋   | 24/36 [07:13<03:38, 18.20s/it] 69%|██████▉   | 25/36 [07:31<03:18, 18.07s/it] 72%|███████▏  | 26/36 [07:50<03:05, 18.58s/it] 75%|███████▌  | 27/36 [08:04<02:33, 17.08s/it] 78%|███████▊  | 28/36 [08:23<02:20, 17.54s/it] 81%|████████  | 29/36 [08:39<01:59, 17.10s/it] 83%|████████▎ | 30/36 [08:49<01:30, 15.06s/it] 86%|████████▌ | 31/36 [09:05<01:17, 15.48s/it] 89%|████████▉ | 32/36 [09:26<01:07, 16.94s/it] 92%|█████████▏| 33/36 [09:41<00:49, 16.36s/it] 94%|█████████▍| 34/36 [10:03<00:36, 18.19s/it] 97%|█████████▋| 35/36 [10:20<00:17, 17.77s/it]100%|██████████| 36/36 [10:36<00:00, 17.16s/it]100%|██████████| 36/36 [10:36<00:00, 17.67s/it]
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Warning: Empty candidate sentence detected; setting raw BERTscores to 0.
