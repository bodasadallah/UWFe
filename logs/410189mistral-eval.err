2024-04-26 08:33:33.419060: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-04-26 08:33:33.419912: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-04-26 08:33:33.486576: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-04-26 08:33:33.650248: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-26 08:33:35.302276: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[nltk_data] Downloading package punkt to
[nltk_data]     /home/abdelrahman.sadallah/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
Map:   0%|          | 0/144 [00:00<?, ? examples/s]Map:   1%|          | 1/144 [00:00<00:34,  4.16 examples/s]Map: 100%|██████████| 144/144 [00:00<00:00, 399.24 examples/s]
Map:   0%|          | 0/144 [00:00<?, ? examples/s]Map:   1%|          | 1/144 [00:00<00:19,  7.20 examples/s]Map: 100%|██████████| 144/144 [00:00<00:00, 822.03 examples/s]
Map:   0%|          | 0/144 [00:00<?, ? examples/s]Map:   1%|          | 1/144 [00:00<00:21,  6.50 examples/s]Map:  35%|███▌      | 51/144 [00:00<00:00, 242.10 examples/s]Map:  74%|███████▍  | 107/144 [00:00<00:00, 368.81 examples/s]Map: 100%|██████████| 144/144 [00:00<00:00, 323.58 examples/s]
`low_cpu_mem_usage` was None, now set to True since model is quantized.
Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/19 [00:37<11:16, 37.56s/it]Loading checkpoint shards:  11%|█         | 2/19 [01:33<13:46, 48.60s/it]Loading checkpoint shards:  16%|█▌        | 3/19 [02:32<14:10, 53.16s/it]Loading checkpoint shards:  21%|██        | 4/19 [03:06<11:24, 45.66s/it]Loading checkpoint shards:  26%|██▋       | 5/19 [03:44<09:58, 42.75s/it]Loading checkpoint shards:  32%|███▏      | 6/19 [04:32<09:40, 44.64s/it]Loading checkpoint shards:  37%|███▋      | 7/19 [05:06<08:13, 41.15s/it]Loading checkpoint shards:  42%|████▏     | 8/19 [05:45<07:23, 40.33s/it]Loading checkpoint shards:  47%|████▋     | 9/19 [35:08<1:36:29, 578.92s/it]Loading checkpoint shards:  53%|█████▎    | 10/19 [35:49<1:01:55, 412.79s/it]Loading checkpoint shards:  58%|█████▊    | 11/19 [57:00<1:30:05, 675.63s/it]Loading checkpoint shards:  63%|██████▎   | 12/19 [57:48<56:31, 484.55s/it]  Loading checkpoint shards:  68%|██████▊   | 13/19 [58:29<35:02, 350.41s/it]Loading checkpoint shards:  74%|███████▎  | 14/19 [59:03<21:14, 254.85s/it]Loading checkpoint shards:  79%|███████▉  | 15/19 [59:46<12:43, 190.79s/it]Loading checkpoint shards:  84%|████████▍ | 16/19 [1:21:33<26:20, 526.90s/it]Loading checkpoint shards:  89%|████████▉ | 17/19 [1:22:06<12:36, 378.34s/it]Loading checkpoint shards:  95%|█████████▍| 18/19 [1:42:04<10:24, 624.64s/it]Loading checkpoint shards: 100%|██████████| 19/19 [1:42:35<00:00, 446.26s/it]Loading checkpoint shards: 100%|██████████| 19/19 [1:42:35<00:00, 323.96s/it]
Traceback (most recent call last):
  File "/home/abdelrahman.sadallah/mbzuai/UWFe/mixtral.py", line 349, in <module>
    inf(val_dataloader,c)
  File "/home/abdelrahman.sadallah/mbzuai/UWFe/mixtral.py", line 262, in inf
    model = AutoModelForCausalLM.from_pretrained(
  File "/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/transformers/models/auto/auto_factory.py", line 563, in from_pretrained
    return model_class.from_pretrained(
  File "/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/transformers/modeling_utils.py", line 3735, in from_pretrained
    dispatch_model(model, **device_map_kwargs)
  File "/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/accelerate/big_modeling.py", line 419, in dispatch_model
    attach_align_device_hook_on_blocks(
  File "/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/accelerate/hooks.py", line 608, in attach_align_device_hook_on_blocks
    add_hook_to_module(module, hook)
  File "/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/accelerate/hooks.py", line 157, in add_hook_to_module
    module = hook.init_hook(module)
  File "/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/accelerate/hooks.py", line 275, in init_hook
    set_module_tensor_to_device(module, name, self.execution_device, tied_params_map=self.tied_params_map)
  File "/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/accelerate/utils/modeling.py", line 391, in set_module_tensor_to_device
    new_value = old_value.to(device)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 39.59 GiB of which 6.62 MiB is free. Process 173524 has 12.62 GiB memory in use. Including non-PyTorch memory, this process has 26.96 GiB memory in use. Of the allocated memory 25.33 GiB is allocated by PyTorch, and 324.96 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
