2024-04-20 22:42:14.313668: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-04-20 22:42:14.314029: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-04-20 22:42:14.315394: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-04-20 22:42:14.322389: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-20 22:42:15.940919: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[nltk_data] Downloading package punkt to
[nltk_data]     /home/abdelrahman.sadallah/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
`low_cpu_mem_usage` was None, now set to True since model is quantized.
Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]Loading checkpoint shards:   5%|▌         | 1/19 [01:28<26:35, 88.64s/it]Loading checkpoint shards:  11%|█         | 2/19 [02:37<21:46, 76.85s/it]Loading checkpoint shards:  16%|█▌        | 3/19 [03:34<18:04, 67.77s/it]Loading checkpoint shards:  21%|██        | 4/19 [04:45<17:19, 69.27s/it]Loading checkpoint shards:  26%|██▋       | 5/19 [05:53<16:03, 68.85s/it]Loading checkpoint shards:  32%|███▏      | 6/19 [07:00<14:43, 67.94s/it]Loading checkpoint shards:  37%|███▋      | 7/19 [08:22<14:32, 72.73s/it]Loading checkpoint shards:  42%|████▏     | 8/19 [09:21<12:29, 68.16s/it]Loading checkpoint shards:  47%|████▋     | 9/19 [12:31<17:44, 106.44s/it]Loading checkpoint shards:  53%|█████▎    | 10/19 [13:23<13:26, 89.56s/it]Loading checkpoint shards:  58%|█████▊    | 11/19 [17:01<17:10, 128.85s/it]Loading checkpoint shards:  63%|██████▎   | 12/19 [18:47<14:14, 122.03s/it]Loading checkpoint shards:  68%|██████▊   | 13/19 [20:27<11:31, 115.30s/it]Loading checkpoint shards:  74%|███████▎  | 14/19 [22:19<09:31, 114.38s/it]Loading checkpoint shards:  79%|███████▉  | 15/19 [23:52<07:11, 107.99s/it]Loading checkpoint shards:  84%|████████▍ | 16/19 [31:20<10:30, 210.17s/it]Loading checkpoint shards:  89%|████████▉ | 17/19 [32:30<05:36, 168.10s/it]Loading checkpoint shards:  95%|█████████▍| 18/19 [41:43<04:43, 283.76s/it]Loading checkpoint shards: 100%|██████████| 19/19 [42:55<00:00, 220.15s/it]Loading checkpoint shards: 100%|██████████| 19/19 [42:55<00:00, 135.56s/it]
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [04:24<2:34:24, 264.70s/it]  6%|▌         | 2/36 [08:34<2:24:53, 255.69s/it]  8%|▊         | 3/36 [13:04<2:24:18, 262.39s/it] 11%|█         | 4/36 [17:44<2:23:40, 269.40s/it] 14%|█▍        | 5/36 [20:53<2:04:09, 240.30s/it] 17%|█▋        | 6/36 [25:03<2:01:47, 243.57s/it] 19%|█▉        | 7/36 [28:06<1:48:11, 223.83s/it] 22%|██▏       | 8/36 [32:31<1:50:34, 236.96s/it] 25%|██▌       | 9/36 [37:02<1:51:22, 247.50s/it] 28%|██▊       | 10/36 [41:44<1:51:53, 258.20s/it] 31%|███       | 11/36 [46:22<1:50:06, 264.26s/it] 33%|███▎      | 12/36 [51:05<1:47:58, 269.93s/it] 36%|███▌      | 13/36 [55:27<1:42:37, 267.70s/it] 39%|███▉      | 14/36 [1:00:06<1:39:23, 271.08s/it] 42%|████▏     | 15/36 [1:04:35<1:34:35, 270.25s/it] 44%|████▍     | 16/36 [1:09:06<1:30:13, 270.67s/it] 47%|████▋     | 17/36 [1:13:43<1:26:15, 272.42s/it] 50%|█████     | 18/36 [1:18:12<1:21:25, 271.43s/it] 53%|█████▎    | 19/36 [1:22:45<1:17:05, 272.08s/it] 56%|█████▌    | 20/36 [1:27:38<1:14:09, 278.10s/it] 58%|█████▊    | 21/36 [1:32:07<1:08:53, 275.59s/it] 61%|██████    | 22/36 [1:36:21<1:02:46, 269.04s/it] 64%|██████▍   | 23/36 [1:40:33<57:12, 264.07s/it]   67%|██████▋   | 24/36 [1:44:57<52:48, 264.04s/it] 69%|██████▉   | 25/36 [1:48:51<46:44, 254.96s/it] 72%|███████▏  | 26/36 [1:52:53<41:48, 250.88s/it] 75%|███████▌  | 27/36 [1:57:15<38:09, 254.38s/it] 78%|███████▊  | 28/36 [2:00:44<32:06, 240.87s/it] 81%|████████  | 29/36 [2:04:17<27:06, 232.37s/it] 83%|████████▎ | 30/36 [2:08:38<24:05, 240.92s/it] 86%|████████▌ | 31/36 [2:13:08<20:48, 249.71s/it] 89%|████████▉ | 32/36 [2:17:38<17:02, 255.62s/it] 92%|█████████▏| 33/36 [2:22:08<13:00, 260.21s/it] 94%|█████████▍| 34/36 [2:24:34<07:31, 225.93s/it] 97%|█████████▋| 35/36 [2:28:52<03:55, 235.45s/it]100%|██████████| 36/36 [2:33:15<00:00, 243.71s/it]100%|██████████| 36/36 [2:33:15<00:00, 255.43s/it]
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Traceback (most recent call last):
  File "/home/abdelrahman.sadallah/mbzuai/UWFe/evaluate_llm.py", line 293, in <module>
    with open(save_file, 'w') as f:
FileNotFoundError: [Errno 2] No such file or directory: 'outputs/outputs/Mixtral-8x7B-v0.1_metrics_0-shots_True-explicit.txt'
[2024-04-21 02:00:48,158] torch.distributed.elastic.multiprocessing.api: [ERROR] failed (exitcode: 1) local_rank: 0 (pid: 3316063) of binary: /home/abdelrahman.sadallah/mambaforge/envs/nlp/bin/python
Traceback (most recent call last):
  File "/home/abdelrahman.sadallah/mambaforge/envs/nlp/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 347, in wrapper
    return f(*args, **kwargs)
  File "/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/torch/distributed/run.py", line 812, in main
    run(args)
  File "/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/torch/distributed/run.py", line 803, in run
    elastic_launch(
  File "/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 135, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/abdelrahman.sadallah/mambaforge/envs/nlp/lib/python3.10/site-packages/torch/distributed/launcher/api.py", line 268, in launch_agent
    raise ChildFailedError(
torch.distributed.elastic.multiprocessing.errors.ChildFailedError: 
============================================================
evaluate_llm.py FAILED
------------------------------------------------------------
Failures:
  <NO_OTHER_FAILURES>
------------------------------------------------------------
Root Cause (first observed failure):
[0]:
  time      : 2024-04-21_02:00:48
  host      : gpu-11
  rank      : 0 (local_rank: 0)
  exitcode  : 1 (pid: 3316063)
  error_file: <N/A>
  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html
============================================================
