2024-04-20 21:51:04.708626: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
2024-04-20 21:51:04.708997: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
2024-04-20 21:51:04.823612: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
2024-04-20 21:51:05.031297: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-04-20 21:51:07.369772: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
[nltk_data] Downloading package punkt to
[nltk_data]     /home/abdelrahman.sadallah/nltk_data...
[nltk_data]   Package punkt is already up-to-date!
`low_cpu_mem_usage` was None, now set to True since model is quantized.
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [01:16<01:16, 76.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:57<00:00, 55.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [01:57<00:00, 58.97s/it]
  0%|          | 0/36 [00:00<?, ?it/s]  3%|▎         | 1/36 [01:34<55:09, 94.56s/it]  6%|▌         | 2/36 [03:07<53:11, 93.86s/it]  8%|▊         | 3/36 [04:41<51:34, 93.76s/it] 11%|█         | 4/36 [06:15<50:00, 93.76s/it] 14%|█▍        | 5/36 [07:46<48:01, 92.96s/it] 17%|█▋        | 6/36 [09:21<46:48, 93.62s/it] 19%|█▉        | 7/36 [11:00<46:06, 95.39s/it] 22%|██▏       | 8/36 [12:40<45:05, 96.64s/it] 25%|██▌       | 9/36 [14:25<44:45, 99.45s/it] 28%|██▊       | 10/36 [15:59<42:16, 97.56s/it] 31%|███       | 11/36 [17:35<40:31, 97.25s/it] 33%|███▎      | 12/36 [19:04<37:50, 94.60s/it] 36%|███▌      | 13/36 [20:25<34:41, 90.50s/it] 39%|███▉      | 14/36 [22:01<33:51, 92.33s/it] 42%|████▏     | 15/36 [23:44<33:24, 95.47s/it] 44%|████▍     | 16/36 [25:12<31:03, 93.18s/it] 47%|████▋     | 17/36 [26:46<29:37, 93.56s/it] 50%|█████     | 18/36 [28:29<28:54, 96.37s/it] 53%|█████▎    | 19/36 [30:05<27:16, 96.24s/it] 56%|█████▌    | 20/36 [31:46<26:01, 97.60s/it] 58%|█████▊    | 21/36 [33:04<22:53, 91.58s/it] 61%|██████    | 22/36 [34:34<21:19, 91.39s/it] 64%|██████▍   | 23/36 [36:11<20:07, 92.92s/it] 67%|██████▋   | 24/36 [37:42<18:27, 92.32s/it] 69%|██████▉   | 25/36 [39:15<16:57, 92.49s/it] 72%|███████▏  | 26/36 [40:50<15:31, 93.19s/it] 75%|███████▌  | 27/36 [42:32<14:24, 96.10s/it] 78%|███████▊  | 28/36 [43:57<12:22, 92.76s/it] 81%|████████  | 29/36 [45:32<10:52, 93.24s/it] 83%|████████▎ | 30/36 [47:02<09:14, 92.44s/it] 86%|████████▌ | 31/36 [48:47<07:59, 95.98s/it] 89%|████████▉ | 32/36 [50:24<06:25, 96.29s/it] 92%|█████████▏| 33/36 [51:59<04:47, 95.96s/it] 94%|█████████▍| 34/36 [53:28<03:08, 94.05s/it] 97%|█████████▋| 35/36 [54:59<01:32, 92.89s/it]100%|██████████| 36/36 [56:25<00:00, 90.93s/it]100%|██████████| 36/36 [56:25<00:00, 94.04s/it]
Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
