model_name_or_path mistralai/Mistral-7B-v0.1
wandb_project nlp804-UWFE-mistral
use_flash_attention_2 True
checkpoint_path None
save_file None
dataset boda/kaneko_data
prompt_key prompt
num_shots 0
explicit_errors False
output_dir /l/users/abdelrahman.sadallah/UWFE-Mixtral
overwrite_output_dir False
do_train False
do_eval True
do_predict False
evaluation_strategy IntervalStrategy.STEPS
prediction_loss_only False
per_device_train_batch_size 4
per_device_eval_batch_size 4
per_gpu_train_batch_size None
per_gpu_eval_batch_size None
gradient_accumulation_steps 1
eval_accumulation_steps None
eval_delay 0
learning_rate 1e-06
weight_decay 0.01
adam_beta1 0.9
adam_beta2 0.999
adam_epsilon 1e-08
max_grad_norm 1.0
num_train_epochs 3.0
max_steps 10000
lr_scheduler_type SchedulerType.LINEAR
lr_scheduler_kwargs {}
warmup_ratio 0.07
warmup_steps 0
log_level passive
log_level_replica warning
log_on_each_node True
logging_dir /l/users/abdelrahman.sadallah/UWFE-Mixtral/runs/Apr11_14-27-12_gpu-14
logging_strategy IntervalStrategy.STEPS
logging_first_step False
logging_steps 100
logging_nan_inf_filter True
save_strategy IntervalStrategy.STEPS
save_steps 500
save_total_limit 3
save_safetensors True
save_on_each_node False
save_only_model False
no_cuda False
use_cpu False
use_mps_device False
seed 42
data_seed None
jit_mode_eval False
use_ipex False
bf16 False
fp16 False
fp16_opt_level O1
half_precision_backend auto
bf16_full_eval False
fp16_full_eval False
tf32 None
local_rank 0
ddp_backend None
tpu_num_cores None
tpu_metrics_debug False
debug []
dataloader_drop_last False
eval_steps 500
dataloader_num_workers 0
dataloader_prefetch_factor None
past_index -1
run_name /l/users/abdelrahman.sadallah/UWFE-Mixtral
disable_tqdm False
remove_unused_columns True
label_names None
load_best_model_at_end True
metric_for_best_model loss
greater_is_better False
ignore_data_skip False
fsdp []
fsdp_min_num_params 0
fsdp_config {'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False}
fsdp_transformer_layer_cls_to_wrap None
accelerator_config AcceleratorConfig(split_batches=False, dispatch_batches=None, even_batches=True, use_seedable_sampler=True)
deepspeed None
label_smoothing_factor 0.0
optim OptimizerNames.ADAMW_TORCH
optim_args None
adafactor False
group_by_length False
length_column_name length
report_to ['tensorboard', 'wandb']
ddp_find_unused_parameters None
ddp_bucket_cap_mb None
ddp_broadcast_buffers None
dataloader_pin_memory True
dataloader_persistent_workers False
skip_memory_metrics True
use_legacy_prediction_loop False
push_to_hub False
resume_from_checkpoint None
hub_model_id None
hub_strategy HubStrategy.EVERY_SAVE
hub_token None
hub_private_repo False
hub_always_push False
gradient_checkpointing False
gradient_checkpointing_kwargs None
include_inputs_for_metrics False
fp16_backend auto
push_to_hub_model_id None
push_to_hub_organization None
push_to_hub_token None
mp_parameters 
auto_find_batch_size False
full_determinism False
torchdynamo None
ray_scope last
ddp_timeout 1800
torch_compile False
torch_compile_backend None
torch_compile_mode None
dispatch_batches None
split_batches None
include_tokens_per_second False
include_num_input_tokens_seen False
neftune_noise_alpha None
sortish_sampler False
predict_with_generate False
generation_max_length None
generation_num_beams None
generation_config None
distributed_state Distributed environment: NO
Num processes: 1
Process index: 0
Local process index: 0
Device: cuda

_n_gpu 1
__cached__setup_devices cuda:0
deepspeed_plugin None
Loading the datasets
{'loss': 2.0678, 'grad_norm': 0.9276246428489685, 'learning_rate': 1.426533523537803e-07, 'epoch': 0.31}
{'loss': 2.0547, 'grad_norm': 0.8042669296264648, 'learning_rate': 2.853067047075606e-07, 'epoch': 0.62}
{'loss': 1.9659, 'grad_norm': 0.9510626792907715, 'learning_rate': 4.2796005706134093e-07, 'epoch': 0.93}
{'loss': 1.8187, 'grad_norm': 0.8889437913894653, 'learning_rate': 5.706134094151212e-07, 'epoch': 1.23}
{'loss': 1.5413, 'grad_norm': 0.6587005257606506, 'learning_rate': 7.132667617689015e-07, 'epoch': 1.54}
{'eval_loss': 1.2101771831512451, 'eval_runtime': 19.9571, 'eval_samples_per_second': 7.215, 'eval_steps_per_second': 1.804, 'epoch': 1.54}
{'loss': 1.3203, 'grad_norm': 0.7330019474029541, 'learning_rate': 8.559201141226819e-07, 'epoch': 1.85}
{'loss': 1.239, 'grad_norm': 0.6560215353965759, 'learning_rate': 9.985734664764621e-07, 'epoch': 2.16}
{'loss': 1.2217, 'grad_norm': 0.717021107673645, 'learning_rate': 9.893536939455855e-07, 'epoch': 2.47}
{'loss': 1.1803, 'grad_norm': 0.6920427680015564, 'learning_rate': 9.78599849446177e-07, 'epoch': 2.78}
{'loss': 1.1933, 'grad_norm': 0.7407870888710022, 'learning_rate': 9.678460049467684e-07, 'epoch': 3.09}
{'eval_loss': 0.9975671768188477, 'eval_runtime': 19.9103, 'eval_samples_per_second': 7.232, 'eval_steps_per_second': 1.808, 'epoch': 3.09}
{'loss': 1.1573, 'grad_norm': 0.7350131273269653, 'learning_rate': 9.570921604473599e-07, 'epoch': 3.4}
{'loss': 1.1338, 'grad_norm': 0.9628914594650269, 'learning_rate': 9.463383159479513e-07, 'epoch': 3.7}
{'loss': 1.155, 'grad_norm': 0.9322221279144287, 'learning_rate': 9.355844714485428e-07, 'epoch': 4.01}
{'loss': 1.1138, 'grad_norm': 0.9610512256622314, 'learning_rate': 9.248306269491342e-07, 'epoch': 4.32}
{'loss': 1.1242, 'grad_norm': 1.0179123878479004, 'learning_rate': 9.140767824497257e-07, 'epoch': 4.63}
{'eval_loss': 0.957818865776062, 'eval_runtime': 19.9359, 'eval_samples_per_second': 7.223, 'eval_steps_per_second': 1.806, 'epoch': 4.63}
{'loss': 1.1097, 'grad_norm': 0.9574369192123413, 'learning_rate': 9.033229379503173e-07, 'epoch': 4.94}
{'loss': 1.0943, 'grad_norm': 1.015299916267395, 'learning_rate': 8.925690934509087e-07, 'epoch': 5.25}
{'loss': 1.1043, 'grad_norm': 1.4349511861801147, 'learning_rate': 8.818152489515002e-07, 'epoch': 5.56}
{'loss': 1.0721, 'grad_norm': 1.3588792085647583, 'learning_rate': 8.710614044520915e-07, 'epoch': 5.86}
{'loss': 1.0772, 'grad_norm': 1.2264106273651123, 'learning_rate': 8.60307559952683e-07, 'epoch': 6.17}
{'eval_loss': 0.9372721910476685, 'eval_runtime': 19.9451, 'eval_samples_per_second': 7.22, 'eval_steps_per_second': 1.805, 'epoch': 6.17}
{'loss': 1.0843, 'grad_norm': 1.2453925609588623, 'learning_rate': 8.495537154532744e-07, 'epoch': 6.48}
{'loss': 1.059, 'grad_norm': 1.225842833518982, 'learning_rate': 8.387998709538659e-07, 'epoch': 6.79}
{'loss': 1.057, 'grad_norm': 1.2886238098144531, 'learning_rate': 8.280460264544575e-07, 'epoch': 7.1}
{'loss': 1.0614, 'grad_norm': 1.0867674350738525, 'learning_rate': 8.172921819550489e-07, 'epoch': 7.41}
{'loss': 1.0489, 'grad_norm': 1.2196131944656372, 'learning_rate': 8.065383374556404e-07, 'epoch': 7.72}
{'eval_loss': 0.9241933822631836, 'eval_runtime': 20.0809, 'eval_samples_per_second': 7.171, 'eval_steps_per_second': 1.793, 'epoch': 7.72}
{'loss': 1.0392, 'grad_norm': 1.3381109237670898, 'learning_rate': 7.957844929562318e-07, 'epoch': 8.02}
{'loss': 1.0567, 'grad_norm': 1.4159146547317505, 'learning_rate': 7.850306484568233e-07, 'epoch': 8.33}
{'loss': 1.0378, 'grad_norm': 1.3907514810562134, 'learning_rate': 7.742768039574148e-07, 'epoch': 8.64}
{'loss': 1.0189, 'grad_norm': 1.4202543497085571, 'learning_rate': 7.635229594580061e-07, 'epoch': 8.95}
{'loss': 1.027, 'grad_norm': 1.4459396600723267, 'learning_rate': 7.527691149585977e-07, 'epoch': 9.26}
{'eval_loss': 0.914671778678894, 'eval_runtime': 19.957, 'eval_samples_per_second': 7.216, 'eval_steps_per_second': 1.804, 'epoch': 9.26}
{'loss': 1.0185, 'grad_norm': 1.6014741659164429, 'learning_rate': 7.420152704591891e-07, 'epoch': 9.57}
{'loss': 1.0168, 'grad_norm': 1.5619878768920898, 'learning_rate': 7.312614259597806e-07, 'epoch': 9.88}
{'loss': 1.0242, 'grad_norm': 1.343953013420105, 'learning_rate': 7.20507581460372e-07, 'epoch': 10.19}
{'loss': 1.0001, 'grad_norm': 1.4523242712020874, 'learning_rate': 7.097537369609635e-07, 'epoch': 10.49}
{'loss': 1.015, 'grad_norm': 1.5230093002319336, 'learning_rate': 6.98999892461555e-07, 'epoch': 10.8}
{'eval_loss': 0.9063341617584229, 'eval_runtime': 19.9496, 'eval_samples_per_second': 7.218, 'eval_steps_per_second': 1.805, 'epoch': 10.8}
{'loss': 0.9971, 'grad_norm': 1.4560399055480957, 'learning_rate': 6.882460479621465e-07, 'epoch': 11.11}
{'loss': 1.0145, 'grad_norm': 1.6761239767074585, 'learning_rate': 6.77492203462738e-07, 'epoch': 11.42}
{'loss': 0.9832, 'grad_norm': 1.6320987939834595, 'learning_rate': 6.667383589633293e-07, 'epoch': 11.73}
{'loss': 0.9751, 'grad_norm': 1.437843918800354, 'learning_rate': 6.559845144639208e-07, 'epoch': 12.04}
{'loss': 0.9821, 'grad_norm': 1.8842188119888306, 'learning_rate': 6.452306699645122e-07, 'epoch': 12.35}
{'eval_loss': 0.8988499045372009, 'eval_runtime': 19.9695, 'eval_samples_per_second': 7.211, 'eval_steps_per_second': 1.803, 'epoch': 12.35}
{'loss': 0.989, 'grad_norm': 1.6189323663711548, 'learning_rate': 6.344768254651037e-07, 'epoch': 12.65}
{'loss': 0.9931, 'grad_norm': 1.6396645307540894, 'learning_rate': 6.237229809656952e-07, 'epoch': 12.96}
{'loss': 0.9522, 'grad_norm': 1.8314659595489502, 'learning_rate': 6.129691364662867e-07, 'epoch': 13.27}
{'loss': 0.987, 'grad_norm': 1.8956689834594727, 'learning_rate': 6.022152919668782e-07, 'epoch': 13.58}
{'loss': 0.9626, 'grad_norm': 1.8588169813156128, 'learning_rate': 5.914614474674696e-07, 'epoch': 13.89}
{'eval_loss': 0.8926963806152344, 'eval_runtime': 20.0414, 'eval_samples_per_second': 7.185, 'eval_steps_per_second': 1.796, 'epoch': 13.89}
{'loss': 0.9793, 'grad_norm': 1.806942105293274, 'learning_rate': 5.807076029680611e-07, 'epoch': 14.2}
{'loss': 0.9699, 'grad_norm': 1.7030376195907593, 'learning_rate': 5.699537584686525e-07, 'epoch': 14.51}
{'loss': 0.9733, 'grad_norm': 1.7576844692230225, 'learning_rate': 5.591999139692439e-07, 'epoch': 14.81}
{'loss': 0.9489, 'grad_norm': 1.7997349500656128, 'learning_rate': 5.484460694698354e-07, 'epoch': 15.12}
{'loss': 0.9512, 'grad_norm': 1.5661449432373047, 'learning_rate': 5.376922249704269e-07, 'epoch': 15.43}
{'eval_loss': 0.8875852227210999, 'eval_runtime': 19.9602, 'eval_samples_per_second': 7.214, 'eval_steps_per_second': 1.804, 'epoch': 15.43}
{'loss': 0.9563, 'grad_norm': 1.7652697563171387, 'learning_rate': 5.269383804710184e-07, 'epoch': 15.74}
{'loss': 0.9581, 'grad_norm': 2.0753560066223145, 'learning_rate': 5.161845359716098e-07, 'epoch': 16.05}
{'loss': 0.9449, 'grad_norm': 2.2905054092407227, 'learning_rate': 5.054306914722013e-07, 'epoch': 16.36}
{'loss': 0.9342, 'grad_norm': 1.9042510986328125, 'learning_rate': 4.946768469727927e-07, 'epoch': 16.67}
{'loss': 0.9509, 'grad_norm': 1.8041778802871704, 'learning_rate': 4.839230024733842e-07, 'epoch': 16.98}
{'eval_loss': 0.8823062777519226, 'eval_runtime': 20.0499, 'eval_samples_per_second': 7.182, 'eval_steps_per_second': 1.796, 'epoch': 16.98}
{'loss': 0.9588, 'grad_norm': 2.199944257736206, 'learning_rate': 4.7316915797397566e-07, 'epoch': 17.28}
{'loss': 0.9342, 'grad_norm': 2.3652477264404297, 'learning_rate': 4.624153134745671e-07, 'epoch': 17.59}
{'loss': 0.9162, 'grad_norm': 2.1438229084014893, 'learning_rate': 4.5166146897515863e-07, 'epoch': 17.9}
{'loss': 0.9563, 'grad_norm': 2.406438112258911, 'learning_rate': 4.409076244757501e-07, 'epoch': 18.21}
{'loss': 0.927, 'grad_norm': 2.1084609031677246, 'learning_rate': 4.301537799763415e-07, 'epoch': 18.52}
{'eval_loss': 0.8776975870132446, 'eval_runtime': 20.0122, 'eval_samples_per_second': 7.196, 'eval_steps_per_second': 1.799, 'epoch': 18.52}
{'loss': 0.9408, 'grad_norm': 2.3205618858337402, 'learning_rate': 4.1939993547693295e-07, 'epoch': 18.83}
{'loss': 0.9243, 'grad_norm': 2.010150194168091, 'learning_rate': 4.0864609097752446e-07, 'epoch': 19.14}
{'loss': 0.9152, 'grad_norm': 2.4146132469177246, 'learning_rate': 3.978922464781159e-07, 'epoch': 19.44}
{'loss': 0.9312, 'grad_norm': 2.1108860969543457, 'learning_rate': 3.871384019787074e-07, 'epoch': 19.75}
{'loss': 0.931, 'grad_norm': 2.3745944499969482, 'learning_rate': 3.7638455747929883e-07, 'epoch': 20.06}
{'eval_loss': 0.8746532201766968, 'eval_runtime': 19.9963, 'eval_samples_per_second': 7.201, 'eval_steps_per_second': 1.8, 'epoch': 20.06}
{'loss': 0.9375, 'grad_norm': 2.7277307510375977, 'learning_rate': 3.656307129798903e-07, 'epoch': 20.37}
{'loss': 0.9063, 'grad_norm': 2.1908061504364014, 'learning_rate': 3.5487686848048175e-07, 'epoch': 20.68}
{'loss': 0.9125, 'grad_norm': 1.9102768898010254, 'learning_rate': 3.4412302398107326e-07, 'epoch': 20.99}
{'loss': 0.9158, 'grad_norm': 2.1772844791412354, 'learning_rate': 3.3336917948166466e-07, 'epoch': 21.3}
{'loss': 0.9178, 'grad_norm': 2.056217908859253, 'learning_rate': 3.226153349822561e-07, 'epoch': 21.6}
{'eval_loss': 0.8711839914321899, 'eval_runtime': 19.9791, 'eval_samples_per_second': 7.208, 'eval_steps_per_second': 1.802, 'epoch': 21.6}
{'loss': 0.9009, 'grad_norm': 2.875617504119873, 'learning_rate': 3.118614904828476e-07, 'epoch': 21.91}
{'loss': 0.911, 'grad_norm': 2.1710662841796875, 'learning_rate': 3.011076459834391e-07, 'epoch': 22.22}
{'loss': 0.9036, 'grad_norm': 2.335961103439331, 'learning_rate': 2.9035380148403055e-07, 'epoch': 22.53}
{'loss': 0.9194, 'grad_norm': 2.340406656265259, 'learning_rate': 2.7959995698462195e-07, 'epoch': 22.84}
{'loss': 0.91, 'grad_norm': 2.382918119430542, 'learning_rate': 2.6884611248521346e-07, 'epoch': 23.15}
{'eval_loss': 0.8689106702804565, 'eval_runtime': 20.0295, 'eval_samples_per_second': 7.189, 'eval_steps_per_second': 1.797, 'epoch': 23.15}
{'loss': 0.9044, 'grad_norm': 2.1785545349121094, 'learning_rate': 2.580922679858049e-07, 'epoch': 23.46}
{'loss': 0.9161, 'grad_norm': 2.0794126987457275, 'learning_rate': 2.473384234863964e-07, 'epoch': 23.77}
{'loss': 0.8925, 'grad_norm': 2.134059190750122, 'learning_rate': 2.3658457898698783e-07, 'epoch': 24.07}
{'loss': 0.9011, 'grad_norm': 2.147711753845215, 'learning_rate': 2.2583073448757932e-07, 'epoch': 24.38}
{'loss': 0.9074, 'grad_norm': 2.4029791355133057, 'learning_rate': 2.1507688998817075e-07, 'epoch': 24.69}
{'eval_loss': 0.8663901090621948, 'eval_runtime': 19.9679, 'eval_samples_per_second': 7.212, 'eval_steps_per_second': 1.803, 'epoch': 24.69}
{'loss': 0.8876, 'grad_norm': 2.6714770793914795, 'learning_rate': 2.0432304548876223e-07, 'epoch': 25.0}
{'loss': 0.8854, 'grad_norm': 2.591276168823242, 'learning_rate': 1.935692009893537e-07, 'epoch': 25.31}
{'loss': 0.8961, 'grad_norm': 2.985572338104248, 'learning_rate': 1.8281535648994515e-07, 'epoch': 25.62}
{'loss': 0.9148, 'grad_norm': 2.222172737121582, 'learning_rate': 1.7206151199053663e-07, 'epoch': 25.93}
{'loss': 0.8939, 'grad_norm': 2.301814317703247, 'learning_rate': 1.6130766749112806e-07, 'epoch': 26.23}
{'eval_loss': 0.8651033043861389, 'eval_runtime': 19.9489, 'eval_samples_per_second': 7.218, 'eval_steps_per_second': 1.805, 'epoch': 26.23}
{'loss': 0.8679, 'grad_norm': 2.327784299850464, 'learning_rate': 1.5055382299171954e-07, 'epoch': 26.54}
{'loss': 0.9012, 'grad_norm': 2.314157485961914, 'learning_rate': 1.3979997849231097e-07, 'epoch': 26.85}
{'loss': 0.9172, 'grad_norm': 2.6386382579803467, 'learning_rate': 1.2904613399290246e-07, 'epoch': 27.16}
{'loss': 0.8955, 'grad_norm': 2.462172746658325, 'learning_rate': 1.1829228949349392e-07, 'epoch': 27.47}
{'loss': 0.8869, 'grad_norm': 2.2090280055999756, 'learning_rate': 1.0753844499408537e-07, 'epoch': 27.78}
{'eval_loss': 0.863672137260437, 'eval_runtime': 19.9704, 'eval_samples_per_second': 7.211, 'eval_steps_per_second': 1.803, 'epoch': 27.78}
{'loss': 0.8921, 'grad_norm': 2.565225839614868, 'learning_rate': 9.678460049467684e-08, 'epoch': 28.09}
{'loss': 0.9027, 'grad_norm': 2.6102840900421143, 'learning_rate': 8.603075599526831e-08, 'epoch': 28.4}
{'loss': 0.8897, 'grad_norm': 2.278552532196045, 'learning_rate': 7.527691149585977e-08, 'epoch': 28.7}
{'loss': 0.8713, 'grad_norm': 2.3779473304748535, 'learning_rate': 6.452306699645123e-08, 'epoch': 29.01}
{'loss': 0.8955, 'grad_norm': 2.193913698196411, 'learning_rate': 5.376922249704269e-08, 'epoch': 29.32}
{'eval_loss': 0.8629227876663208, 'eval_runtime': 20.0844, 'eval_samples_per_second': 7.17, 'eval_steps_per_second': 1.792, 'epoch': 29.32}
{'loss': 0.8786, 'grad_norm': 2.421581268310547, 'learning_rate': 4.301537799763416e-08, 'epoch': 29.63}
{'loss': 0.8883, 'grad_norm': 2.192009687423706, 'learning_rate': 3.2261533498225615e-08, 'epoch': 29.94}
{'loss': 0.894, 'grad_norm': 2.850391149520874, 'learning_rate': 2.150768899881708e-08, 'epoch': 30.25}
{'loss': 0.8986, 'grad_norm': 2.806851863861084, 'learning_rate': 1.075384449940854e-08, 'epoch': 30.56}
{'loss': 0.8964, 'grad_norm': 3.030280828475952, 'learning_rate': 0.0, 'epoch': 30.86}
{'eval_loss': 0.8626428842544556, 'eval_runtime': 19.9199, 'eval_samples_per_second': 7.229, 'eval_steps_per_second': 1.807, 'epoch': 30.86}
{'train_runtime': 17832.2185, 'train_samples_per_second': 2.243, 'train_steps_per_second': 0.561, 'train_loss': 1.025578377532959, 'epoch': 30.86}
Training completed. Model saved. at  /l/users/abdelrahman.sadallah/UWFE-Mixtral/mistralai/Mistral-7B-v0.1
ending 
