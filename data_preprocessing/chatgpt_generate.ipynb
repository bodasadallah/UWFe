{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, AsyncOpenAI\n",
    "import asyncio\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "client = OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\"))\n",
    "from tqdm import tqdm   \n",
    "import emoji\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(prompt,error,correct,wrong_token,correct_token):\n",
    "    full_prompt = f'''{prompt}\n",
    "Erroneous sentence: \n",
    "{error}\n",
    "Correct sentence: \n",
    "{correct}'''\n",
    "    return full_prompt\n",
    "\n",
    "\n",
    "def save_results(temp, file_name):\n",
    "\n",
    "    ## Initialize the file if it does not exist\n",
    "    if not os.path.exists(file_name):\n",
    "        with open(file_name,'w') as file:\n",
    "            json.dump([],file)\n",
    "    \n",
    "    file_data = []\n",
    "    with open(file_name,'r') as file:\n",
    "        file_data = json.load(file)\n",
    "\n",
    "    file_data.extend(temp)\n",
    "    with open(file_name,'w') as file:\n",
    "        # file.seek(0)\n",
    "        json.dump(file_data,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data_path = '../data/explanations_data/json/train.json'\n",
    "\n",
    "\n",
    "data = []\n",
    "with open(data_path, 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(json.loads(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'source'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 21\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39m# with open(chatgpt_outputs_file, 'a') as f:\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(offset,\u001b[39m11691\u001b[39m)):\n\u001b[1;32m     18\u001b[0m     \n\u001b[1;32m     19\u001b[0m     \u001b[39m# idx = idx + offset\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     error \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(data[idx][\u001b[39m'\u001b[39;49m\u001b[39msource\u001b[39;49m\u001b[39m'\u001b[39;49m])\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m[NONE]\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m     22\u001b[0m     correct \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(data[idx][\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m])\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m[NONE]\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m     24\u001b[0m     concat \u001b[39m=\u001b[39m data[idx][\u001b[39m'\u001b[39m\u001b[39mtarget\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m [\u001b[39m'\u001b[39m\u001b[39m[SEP]\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m data[idx][\u001b[39m'\u001b[39m\u001b[39msource\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'source'"
     ]
    }
   ],
   "source": [
    "model_name = 'gpt-3.5-turbo'\n",
    "# base_prompt='''\n",
    "# The following is a sentence that contains only one grammatical error. The line after that contains the error word, and the line after that contains the correction.\n",
    "# Please output a simple explanation of the error and the correction. After that, provide 3 examples of erroneous sentences and their corrections, that contain the same error and correction as the original sentence. Use this format for the examples:\n",
    "# Error:\n",
    "# Correction:\n",
    "# '''\n",
    "base_prompt='''The next two lines contain an erroneous sentence and its correction. Output a simple explanation of the error and the correction. After that, provide three examples that contain the same error.  Only output a valid JSON. The JSON must have these fields: explanation, example1_erroneous, example1_correct, example2_erroneous, example2_correct, example3_erroneous, and example3_correct.'''\n",
    "chatgpt_outputs_file = f'../data/cahtgpt_outputs/{model_name}_outputs.json'\n",
    "num_examples = 0\n",
    "# num_examples = 2000\n",
    "\n",
    "save_temps = []\n",
    "\n",
    "offset = 0\n",
    "# with open(chatgpt_outputs_file, 'a') as f:\n",
    "for idx in tqdm(range(offset,num_examples)):\n",
    "    \n",
    "    # idx = idx + offset\n",
    "\n",
    "    error = ' '.join(data[idx]['source']).replace('[NONE]', '').strip()\n",
    "    correct = ' '.join(data[idx]['target']).replace('[NONE]', '').strip()\n",
    "\n",
    "    concat = data[idx]['target'] + ['[SEP]'] + data[idx]['source']\n",
    "\n",
    "    correct_token = concat[data[idx]['correction_index'][0]]#.replace('[NONE]', '').strip()\n",
    "    wrong_token = concat[data[idx]['correction_index'][1]]#.replace('[NONE]', '').strip()\n",
    "\n",
    "\n",
    "    final_prompt = create_prompt(base_prompt,error,correct,wrong_token,correct_token)\n",
    "    \n",
    "    try:\n",
    "      # correct_answers.append(clue[\"target\"])\n",
    "      clue_message = {\"role\": \"user\", \"content\":final_prompt}\n",
    "      completion = client.chat.completions.create(\n",
    "        # request_timeout=15,\n",
    "        model=model_name,\n",
    "        response_format={\"type\" : \"json_object\"}, ## Add jsno output\n",
    "        messages=[\n",
    "          # system_message,\n",
    "          clue_message\n",
    "        ]\n",
    "      )\n",
    "\n",
    "      response = completion.choices[0].message.content.lower()\n",
    "      response = json.loads(response)\n",
    "      save_temps.append({'idx': idx, 'error': error,'correct': correct,'correct_token' : correct_token, 'wrong_token': wrong_token, 'chatgpt_response': response, 'prompt': final_prompt, 'model': model_name})\n",
    "    except:\n",
    "      save_temps.append({'idx': idx})\n",
    "  \n",
    "\n",
    "    if idx % 100 == 0 or idx == num_examples - 1:\n",
    "      save_results(save_temps,chatgpt_outputs_file)\n",
    "      save_temps = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 11690}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[11690]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('/home/abdelrahman.sadallah/mbzuai/UWFe/data/cahtgpt_outputs/gpt-3.5-turbo_outputs.json','r') as f:\n",
    "    generated_data = json.load(f)\n",
    "\n",
    "train_data = []\n",
    "total = 0\n",
    "cnt = 0\n",
    "for l in generated_data:\n",
    "    if 'chatgpt_response' not in l or    l['chatgpt_response'] == None:\n",
    "        cnt += 1\n",
    "        continue\n",
    "\n",
    "    l['error_type'] = data[l['idx']]['error_type']\n",
    "\n",
    "\n",
    "with open('/home/abdelrahman.sadallah/mbzuai/UWFe/data/cahtgpt_outputs/gpt3.5_generated_training.json','w') as f:\n",
    "    json.dump(generated_data,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 15187, 15187)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt, total, len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['target', 'source', 'evidence_index', 'correction_index', 'error_type', 'predicted_parsing_order', 'origin'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[15186].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(generated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "error_type\n",
       "Preposition                     2079\n",
       "Verb Tense                      2046\n",
       "Number                          1728\n",
       "Collocation                     1609\n",
       "Others                          1293\n",
       "POS Confusion                   1084\n",
       "Subject-Verb Agreement          1016\n",
       "Article                          873\n",
       "Possessive                       846\n",
       "Gerund                           799\n",
       "Infinitives                      723\n",
       "Auxiliary Verb                   332\n",
       "Pronoun-Antecedent Agreement     325\n",
       "Transitive Verb                  259\n",
       "Participle                       174\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['error_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': ['But',\n",
       "  ',',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'it',\n",
       "  'is',\n",
       "  'short',\n",
       "  'distance',\n",
       "  'does',\n",
       "  \"n't\",\n",
       "  'mean',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  'easy',\n",
       "  'or',\n",
       "  'anything',\n",
       "  'like',\n",
       "  'that',\n",
       "  '.'],\n",
       " 'source': ['But',\n",
       "  ',',\n",
       "  'the',\n",
       "  'fact',\n",
       "  'that',\n",
       "  'it',\n",
       "  'is',\n",
       "  'short',\n",
       "  'distance',\n",
       "  'does',\n",
       "  \"n't\",\n",
       "  'mean',\n",
       "  'it',\n",
       "  'will',\n",
       "  'be',\n",
       "  'easy',\n",
       "  'or',\n",
       "  'something',\n",
       "  'like',\n",
       "  'that',\n",
       "  '.'],\n",
       " 'evidence_index': [],\n",
       " 'correction_index': [17, 39],\n",
       " 'error_type': 'Possessive',\n",
       " 'predicted_parsing_order': {'11': 3,\n",
       "  '15': 2,\n",
       "  '17': 1,\n",
       "  '18': 2,\n",
       "  '19': 3,\n",
       "  '20': 3,\n",
       "  '33': 3,\n",
       "  '37': 2,\n",
       "  '39': 1,\n",
       "  '40': 2,\n",
       "  '41': 3,\n",
       "  '42': 3},\n",
       " 'origin': 'A'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
